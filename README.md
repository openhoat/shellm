# SheLLM - AI-Powered Terminal

Un terminal moderne alimentÃ© par l'intelligence artificielle avec Ollama, inspirÃ© de WARP. SheLLM vous permet de dÃ©crire ce que vous voulez faire en langage naturel et l'IA gÃ©nÃ¨re les commandes shell appropriÃ©es.

## ğŸš€ FonctionnalitÃ©s

- **Terminal de base** : Interface de terminal complÃ¨te avec xterm.js
- **IA IntÃ©grÃ©e** : GÃ©nÃ©ration de commandes shell Ã  partir de descriptions en langage naturel
- **Support Ollama** : Connexion configurable Ã  des instances Ollama (locales ou distantes)
- **Interface moderne** : Design sombre par dÃ©faut avec thÃ¨me clair optionnel
- **Configuration flexible** : URL Ollama, modÃ¨le, tempÃ©rature, et plus encore
- **Historique** : Suivi des conversations et des commandes exÃ©cutÃ©es

## ğŸ“‹ PrÃ©requis

- Node.js 18+ et npm
- Ollama installÃ© et en cours d'exÃ©cution (pour l'utilisation locale)
- Python 3 et make (pour la compilation de node-pty sur Linux)

## ğŸ”§ Installation

### 1. Cloner le projet

```bash
git clone <repository-url>
cd shellm
```

### 2. Installer les dÃ©pendances

```bash
npm install
```

### 3. Installer et configurer Ollama

#### Installation d'Ollama

Visitez [ollama.ai](https://ollama.ai) et suivez les instructions d'installation pour votre systÃ¨me d'exploitation.

#### DÃ©marrer Ollama

```bash
ollama serve
```

#### TÃ©lÃ©charger un modÃ¨le

```bash
ollama pull llama2
# ou tout autre modÃ¨le de votre choix
```

#### Utilisation d'une instance distante

Si vous utilisez Ollama sur une machine distante, configurez l'URL dans le panneau de configuration de SheLLM.

## ğŸ® Utilisation

### Mode dÃ©veloppement

```bash
npm run dev
```

Cela lancera :
- Le serveur de dÃ©veloppement Vite (http://localhost:5173)
- L'application Electron

### Build pour production

```bash
npm run build
```

### CrÃ©er des exÃ©cutables

#### Linux

```bash
npm run dist:linux
```

#### macOS

```bash
npm run dist:mac
```

#### Windows

```bash
npm run dist:win
```

Les fichiers exÃ©cutables seront crÃ©Ã©s dans le dossier `release/`.

## ğŸ“– Guide d'utilisation

### PremiÃ¨re utilisation

1. Lancez l'application avec `npm run dev`
2. Cliquez sur l'icÃ´ne d'engrenage en haut Ã  droite pour ouvrir la configuration
3. Configurez l'URL de votre instance Ollama (par dÃ©faut : `http://localhost:11434`)
4. Cliquez sur "Tester la connexion" pour vÃ©rifier la connexion
5. SÃ©lectionnez le modÃ¨le que vous souhaitez utiliser
6. Cliquez sur "Enregistrer"

### Utiliser l'IA

1. Dans le panneau de droite (AI Assistant), tapez votre demande en langage naturel
   - Exemple : "Liste tous les fichiers de plus de 10MB dans le dossier courant"
2. L'IA analysera votre demande et proposera une commande shell
3. Vous pouvez :
   - **ExÃ©cuter** : Lancer directement la commande dans le terminal
   - **Modifier** : Ajuster la commande avant exÃ©cution
   - **Annuler** : Ignorer la proposition

### Utiliser le terminal

Le terminal de gauche fonctionne comme un terminal classique. Vous pouvez :
- Tapez des commandes directement
- Naviguer dans les dossiers
- ExÃ©cuter n'importe quelle commande shell

## âš™ï¸ Configuration

### Ollama

- **URL** : Adresse de votre instance Ollama (locale ou distante)
- **ClÃ© API** : Optionnel, si votre instance Ollama nÃ©cessite une authentification
- **ModÃ¨le** : ModÃ¨le Ollama Ã  utiliser (llama2, mistral, etc.)
- **TempÃ©rature** : ContrÃ´le la crÃ©ativitÃ© de l'IA (0 = plus prÃ©cis, 1 = plus crÃ©atif)
- **Max Tokens** : Nombre maximum de tokens dans la rÃ©ponse

### Interface

- **ThÃ¨me** : Sombre (par dÃ©faut) ou Clair
- **Taille de police** : Ajustez la taille du texte (10-20px)

## ğŸ—ï¸ Architecture

### Structure du projet

```
shellm/
â”œâ”€â”€ electron/              # Processus principal Electron
â”‚   â”œâ”€â”€ main.ts           # Point d'entrÃ©e
â”‚   â”œâ”€â”€ preload.ts        # Script de prÃ©chargement
â”‚   â”œâ”€â”€ ipc-handlers/     # Handlers IPC
â”‚   â”‚   â”œâ”€â”€ terminal.ts   # Gestion du terminal
â”‚   â”‚   â”œâ”€â”€ ollama.ts     # Service Ollama
â”‚   â”‚   â””â”€â”€ config.ts     # Gestion de la configuration
â”‚   â””â”€â”€ tsconfig.json     # Configuration TypeScript
â”œâ”€â”€ src/                   # Processus de rendu (React)
â”‚   â”œâ”€â”€ components/       # Composants React
â”‚   â”‚   â”œâ”€â”€ Terminal.tsx
â”‚   â”‚   â”œâ”€â”€ ChatPanel.tsx
â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â””â”€â”€ ConfigPanel.tsx
â”‚   â”œâ”€â”€ store/            # Gestion d'Ã©tat (Zustand)
â”‚   â”œâ”€â”€ types/            # Types TypeScript
â”‚   â”œâ”€â”€ App.tsx
â”‚   â”œâ”€â”€ main.tsx
â”‚   â””â”€â”€ App.css
â”œâ”€â”€ shared/               # Code partagÃ©
â”‚   â””â”€â”€ types.ts          # Types TypeScript communs
â”œâ”€â”€ dist/                 # Build React (gÃ©nÃ©rÃ©)
â”œâ”€â”€ dist-electron/        # Build Electron (gÃ©nÃ©rÃ©)
â”œâ”€â”€ release/              # ExÃ©cutables (gÃ©nÃ©rÃ©)
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ vite.config.ts
â””â”€â”€ README.md
```

### Technologies utilisÃ©es

- **Electron** : Framework d'applications de bureau
- **React** : BibliothÃ¨que UI
- **TypeScript** : Typage statique
- **Vite** : Build tool et serveur de dÃ©veloppement
- **xterm.js** : Ã‰mulateur de terminal
- **node-pty** : Ã‰mulation de terminal PTY
- **Zustand** : Gestion d'Ã©tat
- **Ollama** : LLM local
- **Axios** : Client HTTP

## ğŸ§ª Tests

SheLLM utilise une architecture de test avec **Vitest** qui sÃ©pare la logique mÃ©tier de la couche Electron, permettant de tester environ **80% du code** sans dÃ©pendre d'Electron.

### Ce qui est testÃ©

âœ… **Logique d'Ã©tat (Zustand)** : Gestion de l'Ã©tat, actions (setConfig, setAiCommand, addToHistory, etc.)
âœ… **Composants React** : Logique de rendu et interactions utilisateur
âœ… **Types partagÃ©s** : Structures de donnÃ©es

### Ce qui n'est pas testÃ©

âŒ **Couche Electron IPC** : `electron/ipc-handlers/`
âŒ **FenÃªtre Electron** : `electron/main.ts`
âŒ **IntÃ©gration complÃ¨te** : Tests E2E

### ExÃ©cution des tests

```bash
# ExÃ©cuter les tests
npm test

# Mode watch (re-exÃ©cution automatique)
npm run test:watch

# Mode UI (interface interactive)
npm run test:ui
```

### Structure des tests

```
src/
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ setup.ts              # Configuration + mocks window.electronAPI
â”‚   â””â”€â”€ README.md             # Documentation des tests
â”œâ”€â”€ store/
â”‚   â””â”€â”€ useStore.test.ts      # Tests du store Zustand
â””â”€â”€ components/
    â””â”€â”€ Header.test.tsx       # Tests des composants React
```

### Ajouter un nouveau test

1. CrÃ©ez un fichier `.test.ts` ou `.test.tsx` dans le dossier correspondant
2. Utilisez les mocks de `window.electronAPI` dÃ©finis dans `src/test/setup.ts`
3. ExÃ©cutez les tests avec `npm test`

## ğŸ“ Conventions de commit

Ce projet utilise **commitlint** pour normaliser les messages de commit selon le format [Conventional Commits](https://www.conventionalcommits.org/).

### Format de commit

```
<type>(<scope>): <subject>
```

### Types autorisÃ©s

- **feat** : Nouvelle fonctionnalitÃ©
- **fix** : Correction de bug
- **docs** : Documentation
- **style** : Style/formatage (pas de changement de code)
- **refactor** : Refactorisation
- **perf** : Performance
- **test** : Tests
- **chore** : Maintenance/Configuration
- **revert** : Revert d'un commit

### Exemples

```bash
git commit -m "feat: ajouter le support de la configuration Ollama"
git commit -m "fix: corriger l'erreur de connexion au terminal"
git commit -m "docs: mettre Ã  jour le README"
git commit -m "style: formater le code avec Biome"
git commit -m "refactor: simplifier la logique du store Zustand"
git commit -m "perf: optimiser les performances de rendu"
git commit -m "test: ajouter des tests pour le composant Terminal"
git commit -m "chore: mettre Ã  jour les dÃ©pendances"
```

### Validation automatique

Un hook Git automatique valide le format de chaque commit avant son application. Si le format est incorrect, le commit sera rejetÃ©.

### Validation manuelle

Pour valider un message de commit manuellement :

```bash
npm run commit:lint
```

## ğŸ”’ SÃ©curitÃ©

- Les commandes proposÃ©es par l'IA ne sont pas exÃ©cutÃ©es automatiquement
- Vous avez toujours le contrÃ´le : validation avant exÃ©cution
- PossibilitÃ© de modifier les commandes avant exÃ©cution
- Configuration stockÃ©e localement avec electron-store

## ğŸ› DÃ©pannage

### Erreur de connexion Ollama

1. VÃ©rifiez qu'Ollama est en cours d'exÃ©cution : `ollama serve`
2. VÃ©rifiez l'URL dans la configuration
3. Testez la connexion depuis votre navigateur : `http://localhost:11434/api/tags`

### ProblÃ¨mes de build

- Linux : Assurez-vous d'avoir Python 3 et make installÃ©s
- macOS : Assurez-vous d'avoir Xcode Command Line Tools installÃ©s
- Windows : Assurez-vous d'avoir les outils de build Visual Studio installÃ©s

### node-pty ne compile pas

Sur Linux :
```bash
sudo apt-get install build-essential python3
npm rebuild node-pty
```

## ğŸ“ Exemples de requÃªtes

- "Liste tous les fichiers Python dans le dossier courant"
- "Trouve les fichiers de plus de 100MB dans /home"
- "Affiche l'utilisation du disque"
- "Compte le nombre de lignes dans tous les fichiers .txt"
- "CrÃ©e un dossier avec la date d'aujourd'hui"

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :

1. Fork le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ©
3. Commit vos changements
4. Push vers la branche
5. Ouvrir une Pull Request

## ğŸ“„ Licence

ISC

## ğŸ‘¨â€ğŸ’» Auteur

Olivier Penhoat <openhoat@gmail.com>

## ğŸ™ Remerciements

- WARP pour l'inspiration
- L'Ã©quipe Ollama pour leur excellent outil
- La communautÃ© open-source